{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [실습] : www.naver.com, www.daum.net, www.yahoo.com 에서 li태그 목록 정보를 불러와 출력해보세요.\n",
    "# [추가] : new 중 하나를 선택해서 주요 기사 내용을 출력하세요 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling_result\n",
      "[\"'경제난 민심 폭발' 스리랑카, 비상사태 선언 이어 내각 사퇴\", '쌍방울그룹 주식 일제히 상한가', \"'산업부 블랙리스트' 소환 임박 검찰의 칼 끝은 청와대? 외[뉴스킹]\", '\"미국, 러시아의 \\'부차 학살\\' 관련 대러 추가 제재 검토 중\"', \"경기남부청, '사전투표 논란' 노정희 선관위원장 수사\", '영공 수호에 청춘 바치고..\"하늘서 편히 쉬시길\"', \"檢 공보관제도 사실 왜곡 논란..검사들 '언론접촉 금지' 풀릴까\", '실외 \\'노마스크\\' 해제될까..\"시기상조\" vs \"야외는 괜찮아\"', '軍 관계자 \"北 백두산 엔진, 요즘 안 쓰는 맹독성 물질\"', \"'집단학살' 부차에서의 전쟁 범죄가 바로 러시아군의 방식\", '목사 딸은 어쩌다가 성교육 강사가 되었나', '\"구시대적 학칙, 학생 인권침해..인권위 전수조사해야\"', '민주, 한덕수 검증두고 신경전..\"이력 상관없이 검증\" vs \"검증 이름의 발목잡기\"', '백악관 \"바이든, 트럼프 기소 원한다고 해\" 보도 부인', \"'스타벅스 아버지' 위기의 스타벅스 구하나\", '\"이 벚나무에 꽃이 피면..서울에 벚꽃이 핍니다\"', '경제부총리 추경호·최상목 2파전.. 법무 한찬식·행안 원희룡 급부상', \"'겁박 vs 사실' 충주시의회, 2년 전 '미술품 논란' 2라운드\", \"민주, '대선 40% 득표' 앞세워 부울경 지선 민심 공략\", '이성문 전 화천대유 대표 \"대장동 사업계획서 작성 정영학이 주도\"', \"[뉴스킹] '산업부 블랙리스트' 소환 임박 검찰의 칼 끝은 청와대? 외\", \"'은행 1곳 몸집이 韓경제의 1.5배'..日 메가뱅크에 '경고음' [정영효의 일본산업 분석]\", \"'멸종위기' 갈라파고스 땅거북 새끼 2마리 英서 인공부화 성공\", '\"강대강 북미관계 지속.. 북한, 핵포기 의사 없는 듯\" [이영광의 거침없이 묻는 인터뷰]', '항상 주가 올랐던 4월, 올해도?', '[무등의 아침] \"한덕수, 민주당 반대 어려운 3요소 갖춰..경기지사 선거, 지방선거 판도 좌우\"', '[인기척] \\'소상공인 대변인\\' 최승재 의원..\"경제적 약자 있어도 정책적 약자 없다\"', '[오마이포토] 이정현, 전남지사 출마 \"경쟁없던 전남에 변화\"', \"'2인 선거구 폐지' 촉구하며 농성하는 민주당 의원들\", '한국보도사진전 대상 작품 감상하는 윤석열 대통령 당선인', '유성구 성북동', '봄기운 전하는 물줄기..아쿠아아트육교 가동 시작']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request   # 원격지 서버 파일 요청\n",
    "from bs4 import BeautifulSoup       # html 파싱\n",
    "\n",
    "url = \"http://www.naver.com\"        # 접속할 주소\n",
    "url2 = \"http://www.yahoo.com\"\n",
    "url3 = \"http://www.daum.net\"\n",
    "url4 = 'https://news.daum.net/'\n",
    "\n",
    "res = urllib.request.urlopen(url4)   # 응답 객체\n",
    "res.geturl()                        # 접속 url 주소를 반환\n",
    "\n",
    "data = res.read()                   # 객체 데이터를 읽어 data 변수 저장\n",
    "# utf-8로 디코딩\n",
    "source = data.decode(\"utf-8\")\n",
    "\n",
    "# html 파싱 - BeautifulSoup\n",
    "html = BeautifulSoup(source,'html.parser')\n",
    "\n",
    "# li_tags = html.find_all('li')\n",
    "# for li in li_tags:\n",
    "#     print(li.string)\n",
    "\n",
    "crawling_data = []\n",
    "\n",
    "i = 0\n",
    "li_news = html.select('.tit_g > a')\n",
    "for a in li_news:\n",
    "    # print(f\"a tag 내용[{i}] : \",a.string.strip())\n",
    "    crawling_data.append(a.string.strip())\n",
    "    i += 1\n",
    "\n",
    "print(\"crawling_result\")\n",
    "print(crawling_data)\n",
    "print(type(crawling_data))\n",
    "\n",
    "# crawling_data.txt로 저장하세요.... (data/crawling_data.txt로 저장)\n",
    "\n",
    "# content = \"\"\n",
    "# wfile = open('data/crawling_data.txt','a',encoding='utf-8')\n",
    "\n",
    "# for content in crawling_data:\n",
    "#     wfile.write(content+\"\\n\")\n",
    "\n",
    "# wfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pickle \n",
    "# - import pickle을 통해서 모듈 임포트가 필요함. \n",
    "# - pickle 모듈을 이용하면 원하는 데이터를 자료형의 변경없이 파일로\n",
    "#   그대로 저장하여 그대로 로드하여 사용이 가능함.\n",
    "# - pickle로 데이터를 저장하거나 불러올 때는 파일을 바이트 형식으로 읽거나 써야한다. \n",
    "# - wb로 데이터를 입력하는 경우, 확장자는 .bin을 사용하는게 좋다.\n",
    "# - 모든 파이썬 데이터 객체를 저장하고 읽을 수 있다.\n",
    "# - 저용량 데이터로 저장되며 효율적으로 저장할 수 있다.\n",
    "#\n",
    "# 저장(save)\n",
    "# pickle.dump(data, file)   -> data = 저장한 소스 데이터 버퍼, \n",
    "#                              file = 저장할 위치(파일)\n",
    "#\n",
    "# 예) import pickle         # 저장\n",
    "#     list = [1,2,3,4,5]\n",
    "#     with open('list.bin','wb') as f:      # 오픈, 작업, 클로즈를 한번에 하기 위해서 with를 사용\n",
    "#         pickle.dump(list,f)\n",
    "#     (원) file = open('list.bin','wb')\n",
    "#          list = [1,2,3,4,5]\n",
    "#          pickle.dump(list,file)\n",
    "#          file.close()\n",
    "#\n",
    "# 예) import pickle         # 로드\n",
    "#     with open('list.bin','rb') as f\n",
    "#         var = pickle.load(f)\n",
    "\n",
    "import pickle\n",
    "# save\n",
    "with open('data/data.pickle1','wb') as file:\n",
    "    pickle.dump(crawling_data,file)\n",
    "print(\"pickle save\")\n",
    "\n",
    "# load\n",
    "with open('data/data.pickle1','rb') as file:\n",
    "    crawling_data = pickle.load(file)\n",
    "print(f\"pickle load\\n{crawling_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle               # 저장\n",
    "list = [1,2,3,4,5]\n",
    "with open('list.bin','wb') as f:\n",
    "    pickle.dump(list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle               # 불러오기\n",
    "with open('list.bin','rb') as f:    \n",
    "    var = pickle.load(f)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 텍스트 전처리 결과 <<<\n",
      "['정경심 뇌종양 · 뇌경색 진단영장 청구 변수 되나', '정경심 최근 뇌종양·뇌경색 진단 새 변수로', '지옥의 고통도 짧다 정경심은 왜 박노해 시로 조국', '뇌종양·뇌경색 진단 받은 정경심검찰 불구속 기소', '정경심 측 백지 공소장으론 재판 못 한다', '조국 전 장관 서울대 복직동문 온라인 커뮤니티 시끌', '조국 사퇴 하루 만에 서울대 복직학내 논란', '대한민국 뒤집어 놓고서울대 복직 한국당 조국', '조국 전 장관 복직 소식에서울대 커뮤니티 찬반 투표', '조국 전 장관 오늘 서울대 법학전문대학원 교수직 복직', '지하철 노사 막판 줄다리기세 가지 핵심 쟁점은', '지하철 ~호선 막판 협상결렬 시 일부터 총', '일 서울 출근길 지하철 대란 현실화되나노사 막판', '내일 서울 지하철 파업하나 노사 마지막 협상 돌입', '서울지하철 파업 밤샘 협상교통혼란 예고', '일본 안 가고 홍콩 못 가고여행업계 가을 성수기도 시름', '유니클로 야나이 회장 이대로 가면 일본은 망할 것', '일본산 맥주 외면옛 명성 회복 불능', '서경덕 교수가 말하는 일본 역사 왜곡 바로잡기', '재팬 일유니클로 년 만에 첫 매출', '억울한 옥살이 또년 복역했는데 이춘재 짓', '화성 사건 이춘재가 자백한 여죄 건은', '범죄의 재구성화성사건에 여죄 더하니 냉각기', '박준영 변호사 화성살인 차 사건 정보공개 요청', '화성 차사건 재심 변호인 수사기록 정보공개 청구', '시진핑 해양경제 발전 성과는 전세계와 나눠야', '日환경상 태풍 유실 방사성 폐기물 환경에 영향 없다', '檢 다음 칼 끝은 한국당소환 않고 재판 넘길까', '조국 후임자 찾기 착수한 靑중폭개각·靑개편 가능성도 솔솔', '석유공사 모르쇠에 수백억 날려국감서 울분 표한 중기 대표', '멧돼지 소탕 군사작전더 빨리 확산될 수도', '文의장 세르비아 대통령에게 한반도 프로세스 지지 당부', '온라인 쇼핑 거래액 조엄지족 잡기 나선 유통가', '방사능 폐기물 태평양 흘러갔을지 모르는데 日보도규제 하는', '애완견과 함께 택시 타려다 강제하차 봉변기사 벌금형', '선택적 정의 선택적 수사 윤석열의 검찰 개혁될까', '조국 없이 진행된 법무부 국감 종료김 빠진 여야 공방', '사회 이모저모', '대통령 부인 김정숙 여사', '카탈루냐 분리독립 추진', '전국은 지금', '', '', '', '', '', '', '', '', '', '', '설리 사망에도 악플은 멈추지 않는다', '[단독]청소년센터서 정신과 약물 강제복용', '설리 가장 폭력적인 곳에서 가장 전투적으로 싸웠던 [기자메모]', '지옥의 고통도 짧다 정경심은 왜 박노해 시로 조국 사퇴 심경 전했나', '재산 빼돌려 호화생활 악의적 고액·상습 체납자 집중 타깃 [국세청 체납 세금과의 전쟁]', '조카와 놀아주던 흑인여성 사살한 美백인경찰관 살인혐의 기소종합', '버스 앞좌석 승객 머리에 체액뿌린 남성 항소심 무죄 반전', '이철희 법무부 검사 블랙리스트 작성 주장대검은 반박종합', '코스피', '', '', '', '코스닥', '', '', '', '다우', '', '', '', '이철희', '한국 북한 축구', '한동훈', '베트남 축구', '월 모의고사', '야구중계', '설리 빈소', '공수처', '이승환', '후쿠오카', '정경심 뇌종양', '해병대 사령관', '배추', '고려고', '정의선', '함박도', '세종시 초등학교 괴한', '조국 서울대', '나경원', '수소차', '홍성흔', '김정임', '이사배', '심은경', '최연수', '태연', '더쇼', '황하나', '김동완', '최준용', '남북 축구', '북한 무관중', '가빈', '', '김정숙', '황인범', '전국 장애인 체육대회', '기아 감독', '이승엽', '김상수', '[정정보도문] 뉴스 시장의 고인 물 제휴평가위원회 관련', '[정정보도] [바코 인사이트] 경기도 농구협회 소속 김종부 심판 갑질 체험기 관련 정정보도문', '[바로잡습니다] 월 일자 면 코링크펀드에 억 출자한 회사 공정위 산하기관서 억 투자 받아 기사', '[바로잡습니다] 월 ~일자 중앙 면 사설']\n",
      ">> 워드 카운트 <<\n",
      "정경심 --> 4\n",
      "조국 --> 10\n",
      "장관 --> 3\n",
      "서울대 --> 4\n",
      "복직 --> 3\n",
      "지하철 --> 4\n",
      "막판 --> 3\n",
      "설리 --> 3\n",
      "축구 --> 3\n",
      ">> 단어 전처리 <<\n",
      "{'정경심': 4, '조국': 10, '장관': 3, '서울대': 4, '복직': 3, '지하철': 4, '막판': 3, '설리': 3, '축구': 3}\n",
      ">> top 5 <<\n",
      "[('조국', 10), ('정경심', 4), ('서울대', 4), ('지하철', 4), ('장관', 3)]\n"
     ]
    }
   ],
   "source": [
    "### 단어 빈도수\n",
    "# 특정 문서의 자료를 토대로 단어들의 출현 빈도수를 이용하여 해당 문서의 특징\n",
    "# 또는 경향을 분석하는 방법을 토픽분석이라고 한다. \n",
    "# \n",
    "\n",
    "import pickle\n",
    "\n",
    "# pickle data file load\n",
    "file = open('data/data.pickle','rb')\n",
    "news_data2 = pickle.load(file)\n",
    "\n",
    "# 텍스트 전처리\n",
    "import re\n",
    "\n",
    "def clean_text(text_string):\n",
    "    # 문장 부호 제거\n",
    "    text_string_re = re.sub(\n",
    "        '[,.?!:\\'\\\"]',\n",
    "        '',\n",
    "        text_string)  # sub(패턴, 변경단어, 변경할 자료)\n",
    "    # 특수문자, 숫자 제거\n",
    "    text_string_re = re.sub(\n",
    "        '[!@#$%^&*()]|[0-9]',\n",
    "       '',\n",
    "        text_string_re)\n",
    "    # 영문 소문자 -> 영문 제거\n",
    "    text_string_re = text_string_re.lower()\n",
    "    text_string_re = re.sub(\n",
    "        '[a-z]',\n",
    "        '',\n",
    "        text_string_re)\n",
    "    # 공백 제거\n",
    "    text_string_re = ' '.join(text_string_re.split())\n",
    "    \n",
    "    return text_string_re\n",
    "\n",
    "## 텍스트 전처리 함수 호출\n",
    "clean_texts = [clean_text(row) for row in news_data2]\n",
    "print(\">>> 텍스트 전처리 결과 <<<\")\n",
    "print(clean_texts)\n",
    "\n",
    "## word count\n",
    "word_count = {}\n",
    "\n",
    "for text in clean_texts:        # 텍스트 -> 문장\n",
    "    for word in text.split():   # 문장 -> 단어\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "\n",
    "print(\">> 워드 카운트 <<\")\n",
    "word_count\n",
    "\n",
    "## 단어 전처리\n",
    "# 불용 단어 제거\n",
    "del word_count['[바로잡습니다]']\n",
    "\n",
    "# 3회 이상 출력 단어 & 2 ~ 4자 단어 지정\n",
    "new_word_count = {}\n",
    "\n",
    "for word,cnt in word_count.items():\n",
    "    if cnt >=3 and len(word) >= 2 and len(word) < 4:\n",
    "        print(word,'-->',word_count[word])\n",
    "        new_word_count[word] = new_word_count.get(word,cnt)\n",
    "print(\">> 단어 전처리 <<\")\n",
    "print(new_word_count)\n",
    "\n",
    "## top word Counter\n",
    "from collections import Counter # 모듈을 추가\n",
    "\n",
    "counter = Counter(new_word_count)\n",
    "top5_word = counter.most_common(5)\n",
    "print(\">> top 5 <<\")\n",
    "print(top5_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file2 = open('data/data.pickle1','rb')\n",
    "new_data3 = pickle.load(file2)\n",
    "\n",
    "# 텍스트 전처리\n",
    "import re\n",
    "\n",
    "def clean_text(text_string):\n",
    "    # 문장 부호 제거\n",
    "    text_string_re = re.sub(\n",
    "        '[,.?!:\\'\\\"]',\n",
    "        '',\n",
    "        text_string)  # sub(패턴, 변경단어, 변경할 자료)\n",
    "    # 특수문자, 숫자 제거\n",
    "    text_string_re = re.sub(\n",
    "        '[!@#$%^&*()]|[0-9]',\n",
    "       '',\n",
    "        text_string_re)\n",
    "    # 영문 소문자 -> 영문 제거\n",
    "    text_string_re = text_string_re.lower()\n",
    "    text_string_re = re.sub(\n",
    "        '[a-z]',\n",
    "        '',\n",
    "        text_string_re)\n",
    "    # 공백 제거\n",
    "    text_string_re = ' '.join(text_string_re.split())\n",
    "    \n",
    "    return text_string_re\n",
    "\n",
    "clean_texts2 = [clean_text(row2) for row2 in new_data3]\n",
    "\n",
    "clean_texts2\n",
    "\n",
    "word_count2 = {}\n",
    "for text in clean_texts2:        # 텍스트 -> 문장\n",
    "    for word in text.split():   # 문장 -> 단어\n",
    "        word_count2[word] = word_count2.get(word, 0) + 1\n",
    "        \n",
    "word_count2\n",
    "\n",
    "new_word_count2 = {}\n",
    "\n",
    "for word,cnt in word_count2.items():\n",
    "    if cnt >=2 and len(word) >= 1 and len(word) < 4:\n",
    "        print(word,'-->',word_count2[word])\n",
    "        new_word_count2[word] = new_word_count2.get(word,cnt)\n",
    "        \n",
    "print(\">> 단어 전처리 <<\")\n",
    "print(new_word_count2)\n",
    "\n",
    "## top word Counter\n",
    "from collections import Counter # 모듈을 추가\n",
    "\n",
    "counter2 = Counter(new_word_count2)\n",
    "top5_word2 = counter2.most_common(5)\n",
    "print(\">> top 5 <<\")\n",
    "print(top5_word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 자료 시각화 (matplotlib 패키지 설치) \n",
    "# pip install matplotlib 으로 설치!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 단어와 출현 빈도수 만들기\n",
    "words = []       # 단어\n",
    "counts = []      # 출현 빈도수\n",
    "\n",
    "print(top5_word)\n",
    "for word, count in top5_word:\n",
    "    words.append(word)\n",
    "    counts.append(count)\n",
    "\n",
    "print(words)\n",
    "print(counts)\n",
    "\n",
    "## pyplot 모듈을 import => plt로 별칭 사용\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 차트에서 한글 지원\n",
    "from matplotlib import font_manager,rc\n",
    "font_name = font_manager.FontProperties(\n",
    "    fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()     # font_manager를 통하여 맑은 고딕 불러오기\n",
    "\n",
    "rc('font',family=font_name)     # 맑은 고딕 적용\n",
    "\n",
    "## 선 그래프\n",
    "print('선 그래프')\n",
    "plt.plot(words,counts)\n",
    "plt.show()\n",
    "\n",
    "## 막대 그래프\n",
    "print(\"막대 그래프\")\n",
    "plt.bar(words, counts)\n",
    "plt.show()\n",
    "\n",
    "## 원형 그래프\n",
    "print('원형 차트')\n",
    "plt.pie(counts,labels=words,autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBase 사용\n",
    "\n",
    "# SQLite3\n",
    "# - 기기 내부에서만 사용할 수 있는 DBMS이다.\n",
    "# - 주로 모바일이나 소형 기기에서 관계형 데이터베이스를 생성해 주는 소프트웨어\n",
    "# - 생성된 DB는 외부에서 접근을 허용하지 않음.\n",
    "# - 파이썬은 SQLite3를 기본으로 제공하고 있어 제약없이 import하여 사용할 수 있음.\n",
    "#\n",
    "# ## 테이블 생성\n",
    "#   Create table [if not exists] table-name(\n",
    "#       column-name data-type-name column-constraint,\n",
    "#       ....   \n",
    "# )\n",
    "#\n",
    "# ## data-tpye\n",
    "#   TEXT : 문자형           ex) TEXT(size)\n",
    "#   NUMBERIC : 숫자형       ex) NUMBERIC\n",
    "#   Integer : 정수형\n",
    "#   REAL : 실수형\n",
    "#   BLOB : 대용량 자료\n",
    "#\n",
    "# ## 제약조건\n",
    "#   PRIMARY KEY : 기본키\n",
    "#   UNIQUE : 중복 불가\n",
    "#   NOT NULL : 생략 불가\n",
    "#   CHECK : 제한 조건\n",
    "#   DEFAULT : 기본값 \n",
    "\n",
    "## CRUD -> Create(Insert), Read(Select), Update(Update), Delete(Delete)\n",
    "\n",
    "## SQLite3 사용 예시\n",
    "\n",
    "## 모듈 import\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# 확인\n",
    "print(sqlite3.sqlite_version_info)  # 버젼 정보 : (3, 37, 2)\n",
    "\n",
    "try:\n",
    "    # DB연동\n",
    "    conn = sqlite3.connect('data/sqlite_db')    # DB 생성 -> 연결객체 생성\n",
    "    \n",
    "    # sql실행 객체\n",
    "    cursor = conn.cursor()      # sql을 실행하고 결과값을 받아서 처리해주는 역할 : cursor()\n",
    "    \n",
    "    # table 생성\n",
    "    sql = 'create table if not exists test_table\\\n",
    "         (name text(10),phone text(15),addr text(50))'\n",
    "    \n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    ## 레코드 추가\n",
    "    # cursor.execute('insert into test_table values\\\n",
    "    #     (\"홍길동\",\"010-1111-1111\",\"산골짜기\")')\n",
    "    # cursor.execute('insert into test_table values\\\n",
    "    #     (\"이순신\",\"010-9999-9999\",\"해남시\")')\n",
    "    # cursor.execute('insert into test_table values\\\n",
    "    #     (\"강감찬\",\"010-2222-2222\",\"평양시\")')\n",
    "    # cursor.execute('insert into test_table values\\\n",
    "    #     (\"이성계\",\"010-3333-3333\",\"개성시\")')    \n",
    "    \n",
    "    # conn.commit()       # DB 반영\n",
    "    \n",
    "    ## 레코드 조회\n",
    "    # cursor.execute('select * from test_table')\n",
    "    # rows = cursor.fetchall()        # 조회 레코드 읽기\n",
    "    \n",
    "    # # 출력1\n",
    "    # for row in rows:\n",
    "    #     print(row)\n",
    "        \n",
    "    # # 출력2\n",
    "    # print('이름 \\t 전화번호        주소')\n",
    "    # for row in rows:\n",
    "    #     print(row[0],'\\t',row[1],'\\t',row[2])\n",
    "    ## 메뉴를 사용하여 다음 코드를 작성하세요.(1. DB출력, 2. DB수정, 3. DB삭제, 0. DB종료)\n",
    "    ## name으로 입력값을 받아서 정보를 수정하는 코드를 작성하세요.\n",
    "    ## name을 입력받아서 레코드를 삭제하는 코드를 작성하세요.\n",
    "    while True:\n",
    "        print('-'*50)\n",
    "        no = input('1. DB출력\\n2. DB수정\\n3. DB삭제\\n0. 종료\\n번호 입력 >>')\n",
    "        if no == '1':\n",
    "            cursor.execute('select * from test_table')\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            print('이름 \\t 전화번호        주소')\n",
    "            for row in rows:\n",
    "                print(row[0],'\\t',row[1],'\\t',row[2])\n",
    "        elif no == '2':\n",
    "            name = input('이름을 입력하세요 : ')\n",
    "            cursor.execute(f\"select * from test_table where name = '{name}'\")\n",
    "            row = cursor.fetchall()\n",
    "            \n",
    "            if row:\n",
    "                new_name = input('수정할 이름을 입력하세요 : ')\n",
    "                new_phone = input('수정할 번호를 입력하세요 : ')\n",
    "                new_addr = input('수정할 주소를 입력하세요 : ')\n",
    "                cursor.execute(f\"update test_table set name='{new_name}',phone='{new_phone}',addr='{new_addr}' where name='{name}'\")\n",
    "                conn.commit()\n",
    "            else:\n",
    "                print('존재하지 않습니다.')\n",
    "        elif no == '3':\n",
    "            name = input('삭제할 이름을 입력하세요 : ')\n",
    "            cursor.execute(f\"delete from test_table where name='{name}'\")    \n",
    "            conn.commit()\n",
    "        elif no == '0':\n",
    "            print('프로그램을 종료합니다.')\n",
    "            break\n",
    "        else:\n",
    "            print('잘못 입력했습니다.')\n",
    "except Exception as e:\n",
    "    print('DB 연동 에러 : ',e)\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling_result\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=100'\n",
    "resp = urllib.request.urlopen(url)\n",
    "\n",
    "data = resp.read()                   # 객체 데이터를 읽어 data 변수 저장\n",
    "# utf-8로 디코딩\n",
    "source = data.decode(\"euc-kr\")\n",
    "# html 파싱 - BeautifulSoup\n",
    "html = BeautifulSoup(source,'html.parser')\n",
    "\n",
    "crawling_data = []\n",
    "\n",
    "li_news = html.select('.cluster')\n",
    "\n",
    "for a in li_news:\n",
    "    # print(f\"a tag 내용[{i}] : \",a.string.strip())\n",
    "    crawling_data.append(a.string)\n",
    "\n",
    "print(\"crawling_result\")\n",
    "print(crawling_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
